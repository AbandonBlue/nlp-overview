{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWRsjCtNloKd"
   },
   "source": [
    "## [keyBERT](https://maartengr.github.io/KeyBERT/)\n",
    "- [è‡ªå·±æ›æ¨¡å‹](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKuASwEWhhBa",
    "outputId": "c2efe44e-b7d3-4349-8432-de425a706a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading https://files.pythonhosted.org/packages/db/fb/822e7094457cd16319291e34aa97b2ef97620da01af94fe557e96a8cc6b9/keybert-0.3.0.tar.gz\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/75/df441011cd1726822b70fbff50042adb4860e9327b99b346154ead704c44/sentence-transformers-1.2.0.tar.gz (81kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 11.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.19.5)\n",
      "Collecting transformers<5.0.0,>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.5MB 38.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.41.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.8.1+cu101)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.9.1+cu101)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 43.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.0.12)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 50.3MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 56.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (4.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.13)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
      "Building wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keybert: filename=keybert-0.3.0-cp37-none-any.whl size=19436 sha256=b7fe8b4baea679def024794a91e4b2dfcf0a66729c3ca1c855959dd915666861\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/ab/2b/bc129895ee956866333f364f1b3beb20efa788e074c03e6b34\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.0-cp37-none-any.whl size=123339 sha256=b7d1b248a7e5c8fef4962ce70a4609b4322bd0d3fa07fe1ceccbe3a7fc109687\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/06/f7/faaa96fdda87462b4fd5c47b343340e9d5531ef70d0eef8242\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers, keybert\n",
      "Successfully installed huggingface-hub-0.0.8 keybert-0.3.0 sacremoses-0.0.45 sentence-transformers-1.2.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4qb5pYBieCk"
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "7b32383d01fe4695aecd70a4329dfc17",
      "138b5b358c4843779f9fe6e06a056aa0",
      "ae9402350f5643c583434f08925377e6",
      "5357ebb9024f41d9bc733a5c529257f6",
      "40763304fcb745ea9c08ac1e5c80580f",
      "a347223aaf374e5692cb5ab572fdc91e",
      "f14034beff874cb194445e6a4928c016",
      "38f2d80a2808438bb9fe16cca2f03d62"
     ]
    },
    "id": "y_32gYFLhp3J",
    "outputId": "76859389-edad-40e9-ab4e-77eb82c02224"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b32383d01fe4695aecd70a4329dfc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244733649.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('blogpost', 0.2089),\n",
       " ('python', 0.1923),\n",
       " ('tutorials', 0.1719),\n",
       " ('macbook', 0.1712),\n",
       " ('thursday', 0.1369)]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"\"\"\n",
    "Towards Data Science\n",
    "Sign in\n",
    "\n",
    "Get started\n",
    "Follow\n",
    "549K Followers\n",
    "Â·\n",
    "Editors' Picks\n",
    "Features\n",
    "Deep Dives\n",
    "Grow\n",
    "Contribute\n",
    "About\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You have 1 free member-only story left this month. Sign up for Medium and get an extra one\n",
    "\n",
    "How to Extract Relevant Keywords with KeyBERT\n",
    "Yet another application of BERT\n",
    "Ahmed Besbes\n",
    "Ahmed Besbes\n",
    "\n",
    "1 day agoÂ·5 min read\n",
    "\n",
    "\n",
    "\n",
    "Image by the author\n",
    "There are many powerful techniques that perform keywords extraction (e.g. Rake, YAKE!, TF-IDF). However, they are mainly based on the statistical properties of the text and donâ€™t necessarily take into account the semantic aspects of the full document.\n",
    "KeyBERT is a minimal and easy-to-use keyword extraction technique that aims at solving this issue. It leverages the BERT language model and relies on the ğŸ¤—transformers library.\n",
    "\n",
    "source: https://github.com/MaartenGr/KeyBERT\n",
    "KeyBERT is developed and maintained by \n",
    "Maarten Grootendorst\n",
    ". So go check his repo (and clone it) if youâ€™re interested in using it.\n",
    "In this post, Iâ€™ll briefly present KeyBERT: how it works and how you can use it\n",
    "PS: If you want to see a video tutorial on how to use KeyBERT and how to embed it in a Streamlit app, you can have a look at my video:\n",
    "\n",
    "Video by the author\n",
    "KeyBERT: a BERT-powered keyword extraction technique\n",
    "You can install KeyBERT with pip.\n",
    "pip install keybert\n",
    "If you need embeddings from other sources than ğŸ¤—transformers, you can install them as well:\n",
    "pip install keybert[flair]\n",
    "pip install keybert[gensim]\n",
    "pip install keybert[spacy]\n",
    "pip install keybert[use]\n",
    "Calling KeyBERT is straightforward: you initialize a keyword extraction model based on a ğŸ¤—transformers model and apply the extract_keywords method on it.\n",
    "\n",
    "source: https://github.com/MaartenGr/KeyBERT\n",
    "How does KeyBERT extract keywords?\n",
    "KeyBERT extracts keywords by performing the following steps:\n",
    "1 â€” The input document is embedded using a pre-trained BERT model. You can pick any BERT model your want from ğŸ¤—transformers. This turns a chunk of text into a fixed-size vector that is meant the represent the semantic aspect of the document\n",
    "2 â€” Keywords and expressions (n-grams) are extracted from the same document using Bag Of Words techniques (such as a TfidfVectorizer or CountVectorizer). This is a classical step that you may be familiar with if youâ€™ve performed keywords extraction in the past\n",
    "\n",
    "Image by the author\n",
    "3 â€” Each keyword is then embedded into a fixed-size vector with the same model used to embed the document\n",
    "\n",
    "Image by the author\n",
    "4 â€” Now that the keywords and the document are represented in the same space, KeyBERT computes a cosine similarity between the keyword embeddings and the document embedding. Then, the most similar keywords (with the highest cosine similarity score) are extracted.\n",
    "\n",
    "Image by the author\n",
    "The idea is pretty simple: you can think of it as an enhanced version of a classical keyword extraction technique in which the BERT language model comes in to add its semantic capability.\n",
    "This doesnâ€™t stop here: KeyBERT includes two methods to introduce diversity in the resulting keywords.\n",
    "1 â€” Max Sum Similarity (MSS)\n",
    "To use this method, you start by setting the top_n argument to a value, say 20. Then 2 x top_n keywords are extracted from the document. Pairwise similarities are computed between these keywords. Finally, the method extracts the most relevant keywords that are the least similar to each other.\n",
    "Hereâ€™s an example from the KeyBERTâ€™s repository:\n",
    "\n",
    "source: https://github.com/MaartenGr/KeyBERT\n",
    "2 â€” Maximal Marginal Relevance (MMR)This method is similar to the previous one: it adds a diversity argument\n",
    "MMR tries to minimize redundancy and maximize the diversity of results in text summarization tasks.\n",
    "It starts by selecting the keywords that are the most similar to the document. Then, it iteratively selects new candidates that are both similar to the document and not similar to the already selected keywords\n",
    "You can choose a low-diversity threshold:\n",
    "\n",
    "source: https://github.com/MaartenGr/KeyBERT\n",
    "or a high one:\n",
    "\n",
    "source: https://github.com/MaartenGr/KeyBERT\n",
    "So far so good, butâ€¦\n",
    "One limitation that KeyBERT may suffer from though is the execution time: if you have large documents and need real-time results, KeyBERT may not be the best solution (unless you have dedicated GPUs in your production environment). The reason being that BERT models are notoriously huge and consume a lot of resources especially when they have to process large documents.\n",
    "You can probably find some hacks to speed up the inference time by picking smaller models (DistilBERT), using mixed precision or even convert your model to ONNX format.\n",
    "If this still doesnâ€™t work out for you, check other classical methods: youâ€™d be surprised by their efficiency despite their relative simplicity.\n",
    "Thanks for reading!\n",
    "Thatâ€™s it for today. I hope youâ€™ll find this small method useful for your NLP projects if youâ€™re performing keywords extraction.\n",
    "You can learn more about KeyBERT here:\n",
    "MaartenGr/KeyBERT\n",
    "KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to create keywords andâ€¦\n",
    "github.com\n",
    "\n",
    "Keyword Extraction with BERT\n",
    "A minimal method for extracting keywords and keyphrases\n",
    "towardsdatascience.com\n",
    "\n",
    "and here:\n",
    "Self-Supervised Contextual Keyword and Keyphrase Retrieval with Self-Labelling\n",
    "In this paper we propose a novel self-supervised approach of keywords and keyphrases retrieval and extraction by anâ€¦\n",
    "www.preprints.org\n",
    "\n",
    "Take care,\n",
    "Sign up for The Variable\n",
    "By Towards Data Science\n",
    "Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss. Take a look.\n",
    "\n",
    "Get this newsletter\n",
    "You'll need to sign in or create an account to receive this newsletter.\n",
    "\n",
    "46\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "Data Science\n",
    "NLP\n",
    "Bert\n",
    "Transformers\n",
    "Machine Learning\n",
    "More from Towards Data Science\n",
    "Follow\n",
    "Your home for data science. A Medium publication sharing concepts, ideas and codes.\n",
    "\n",
    "Antony Henao\n",
    "\n",
    "Â·1 day ago\n",
    "\n",
    "Data Engineers Shouldnâ€™t Write Airflow Dags â€” Part 2\n",
    "A framework proposal for Apache Airflow\n",
    "\n",
    "Photo by Richard Horvath on Unsplash\n",
    "This is the second article about why Data Engineers shouldnâ€™t write Airflow DAGs. In this new article, we are going to introduce a framework proposal for Apache Airflow.\n",
    "This article aims to shed some light on how building a framework can help you solve some of the problems related to DAG writing.\n",
    "In this new article, Iâ€™m going to do a short recap about the first part. So, it is not necessary to read it. Though, you should consider reading it if you want a more detailed explanation of the things Iâ€™m going to address in this one.\n",
    "Data Engineers Shouldnâ€™t Write Airflow Dags â€” Part 1\n",
    "towardsdatascience.com\n",
    "\n",
    "Why Data Engineer shouldnâ€™t write DAGs\n",
    "As Iâ€¦\n",
    "Read more Â· 7 min read\n",
    "\n",
    "88\n",
    "\n",
    "\n",
    "1\n",
    "\n",
    "\n",
    "Bilal Mahmood Khan\n",
    "\n",
    "Â·1 day ago\n",
    "\n",
    "Calculating Internal Rate of Return (IRR) in BigQuery\n",
    "A step-by-step guide to implementing Excelâ€™s IRR function in BigQuery\n",
    "Internal Rate of Return (IRR) is a common calculation that often comes up in finance. In this blogpost, I will show how to build a query in BigQuery that carries out the calculation equivalent to Excelâ€™s IRR function. This is helpful if the cashflows are stored in a BigQuery table and you want to calculate IRR without moving the data to Excel, or if you want to use BigQuery as a source for data visualizations and BI.\n",
    "\n",
    "Photo by Scott Graham on Unsplash\n",
    "1. Background: Internal Rate of Return (IRR) and Net Present Value (NPV)\n",
    "Internal Rate of Return (IRR) is the rate of return at which the Net Present Value of all cashflows resulting from an investmentâ€¦\n",
    "Read more Â· 6 min read\n",
    "\n",
    "30\n",
    "\n",
    "\n",
    "\n",
    "Dea Bardhoshi\n",
    "\n",
    "Â·1 day ago\n",
    "\n",
    "Healthiest Cities in the US: Part 1, Food\n",
    "How healthy are US cities?\n",
    "\n",
    "Photo by Haseeb Jamil on Unsplash\n",
    "I have been thinking about using data science and statistics in the context of urban analysis, especially about the question of how healthy US cities are. In these multi-part stories, we are going to be analysing this question using data science. At this moment, I plan on dividing the stories like this: food, recreational spaces, and work-life balance. For this first part, we are going to be focusing on food: namely how common fast food chains are throughout American cities, and how accessible grocery bought food is to the American people. Letâ€™s get started:\n",
    "Data:\n",
    "Fast Food Data: https://www.kaggle.com/datafiniti/fast-food-restaurants\n",
    "Tools:\n",
    "Jupyter Notebooks\n",
    "â€¦\n",
    "Read more Â· 7 min read\n",
    "\n",
    "26\n",
    "\n",
    "\n",
    "\n",
    "Mateusz KwaÅ›niak\n",
    "\n",
    "Â·1 day ago\n",
    "\n",
    "Kubeflow (is not) for Dummies\n",
    "Deploy and destroy Kubeflow on EKS with one script, no sweat\n",
    "\n",
    "Figure 1. Kubeflow Dashboard (Source: Kubeflow docs)\n",
    "Tools, libraries, frameworks are created to make our work easier. They introduce new functionalities, simplify code, reduce boilerplate, automate stuff.\n",
    "Imagine your project with no dependencies, imagine you need to replace a single function call (e.g. yaml.safe_load) with your own piece of code for that functionality. All these tools make applications easier to build and maintain, develop and deploy. But what if these tools themselves are difficult to be deployed? Ouch.\n",
    "Introducing Kubeflow\n",
    "I wonâ€™t lie â€” thereâ€™s no coincidence that I introduce Kubeflow right after writing that tools can be difficult to be deployed. â€¦\n",
    "Read more Â· 5 min read\n",
    "\n",
    "23\n",
    "\n",
    "\n",
    "\n",
    "Harsh Maheshwari\n",
    "\n",
    "Â·1 day ago\n",
    "\n",
    "WANT TO LEARN SQL QUICKLY?\n",
    "Learn Essential SQL Skills for Data Scientists in 5 Minutes\n",
    "Learn essential SQL skills to make your data science resume more attractive\n",
    "\n",
    "Photo by Joshua Sortino on Unsplash\n",
    "Letâ€™s start with an interesting fact. SQL is the most required skill for data analysts and data engineers and the third most required skill for data scientists. Well, this fact simply tells you how important it is to know SQL.\n",
    "Okay, but why is SQL a highly desired skill set? Usually, data scientists work with data frames in Python or R. However, the vast amount of data in todayâ€™s data science canâ€™t be completely loaded into a data frame or even into a .csv file. For such cases, an SQL database is required. SQL is very simple and easy toâ€¦\n",
    "Read more Â· 6 min read\n",
    "\n",
    "121\n",
    "\n",
    "\n",
    "\n",
    "Read more from Towards Data Science\n",
    "More From Medium\n",
    "Whatâ€™s New in Python 3.10?\n",
    "James Briggs in Towards Data Science\n",
    "\n",
    "6 Python Projects You Can Finish in a Weekend\n",
    "Frank Andrade in Towards Data Science\n",
    "\n",
    "3 Awesome Python Libraries That You Should Know About\n",
    "Ismael Araujo in Towards Data Science\n",
    "\n",
    "20 Lessons learned going from Junior Data Scientist to Chief Data Scientist\n",
    "Mathias Gruber in Towards Data Science\n",
    "\n",
    "Why Youâ€™ll Quit Your Data Science Job\n",
    "Vicky Yu in Towards Data Science\n",
    "\n",
    "Dual Boot is Dead: The Post Mortem\n",
    "Dimitris Poulopoulos in Towards Data Science\n",
    "\n",
    "M1 MacBook Pro vs. Intel i9 MacBook Proâ€Šâ€”â€ŠUltimate Data Science Comparison\n",
    "Dario RadeÄiÄ‡ in Towards Data Science\n",
    "\n",
    "Data Scientists and ML Engineers Are Luxury Employees\n",
    "Adrien Biarnes in Towards Data Science\n",
    "\n",
    "About\n",
    "\n",
    "Help\n",
    "\n",
    "Legal\n",
    "\"\"\"\n",
    "\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "keywords = kw_model.extract_keywords(doc)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNHUC1Kziao1",
    "outputId": "9f336d77-a3a7-4149-fe48-8ff0a936a787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('projects finish weekend', 0.1414),\n",
       " ('macbook pro ultimate', 0.4011),\n",
       " ('science hands tutorials', 0.1785),\n",
       " ('549k followers editors', 0.2469),\n",
       " ('medium new python', -0.0041)]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSSæ–¹æ³•\n",
    "kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', \n",
    "                              use_maxsum=True, nr_candidates=20, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvpY7BZzjNCQ",
    "outputId": "c44e69cf-c2fd-451d-d558-6d7d415555e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science 20 lessons', 0.507),\n",
       " ('writing tools difficult', 0.0996),\n",
       " ('grocery bought food', 0.2161),\n",
       " ('github com keyword', 0.3079),\n",
       " ('airflow dags new', 0.2573)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MMR\n",
    "\n",
    "kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', \n",
    "                              use_mmr=True, diversity=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhnsi-h_mJvy"
   },
   "source": [
    "### ä¸­æ–‡ç‰ˆæœ¬\n",
    "- ä½¿ç”¨ distiluse-base-multilingual-cased-v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQwfMNtqkD_D"
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "    å»ºç«‹è³‡æ–™ç§‘å­¸åœ˜éšŠ\n",
    "éš¨è‘—è³‡æ–™ç§‘å­¸åœ¨å„é ˜åŸŸçš„é–‹ç™¼ã€æ‡‰ç”¨æŒçºŒå‡æº«ï¼Œå»ºç«‹å°ˆæ¥­åˆ†å·¥çš„åœ˜éšŠæ˜¯å¿…ç¶“ä¹‹è·¯ã€‚è³‡æ–™ç§‘å­¸åœ˜éšŠçš„å»ºç«‹æœƒé¢è‡¨è‘—ä¸ä¸€æ¨£çš„æŒ‘æˆ°ï¼Œè®“æˆ‘å€‘è·Ÿè‘— Wendy äº†è§£å…¶åœ¨ Kaggle é¢è‡¨çš„æŒ‘æˆ°ã€‚\n",
    "æ´»å‹•ä¸»è¾¦å–®ä½ï¼šTaiwan Data Science Meetup å°ç£è³‡æ–™ç§‘å­¸ç¤¾ç¾¤\n",
    "å¤§ç¶±ï¼š\n",
    "ä¸€ã€ä»‹ç´¹ (Introduction)\n",
    "äºŒã€è³‡æ–™åŸºç¤è¨­æ–½ (Data infrastructure)\n",
    "ä¸‰ã€åˆ†æç³»çµ± (Analytics systems)\n",
    "å››ã€æ©Ÿå™¨å­¸ç¿’ (Machine learning)\n",
    "äº”ã€Q&A\n",
    "ä¸€ã€ä»‹ç´¹ (Introduction)\n",
    "\n",
    "è¬›è€…: Wendy Kan\n",
    "è¬›è€…ä»‹ç´¹ï¼š\n",
    "åœ¨ç”Ÿé†«å·¥ç¨‹è·Ÿé†«å­¸MLç•Œæ‰“æ»¾å¹¾å¹´å¾Œï¼ŒWendy åœ¨ Kaggle åšäº†å››å¹´çš„è³‡æ–™ç§‘å­¸å®¶ï¼Œä¸»è¦è² è²¬è¨­è¨ˆMLæ¯”è³½ã€‚éå»å…©å¹´é–“ï¼ŒWendy åœ¨ Kaggle æˆç«‹äº†ä¸€å€‹å°Data teamã€‚Wendy å°‡æœƒåˆ†äº«å¾é›¶é–‹å§‹æˆç«‹ä¸€å€‹å°Data teamé‡åˆ°çš„æŒ‘æˆ°ã€‚Wendy ç›®å‰å·²ç¶“é›¢é–‹ Kaggle åŠ å…¥äº†Google Ads AI teamï¼Œä¸éä»ç„¶èˆ‡Wendyå¾…äº†å…­å¹´çš„ Kaggle æœ‰å‹å¥½çš„åˆä½œé—œä¿‚ã€‚\n",
    "äºŒã€è³‡æ–™åŸºç¤è¨­æ–½ (Data infrastructure)\n",
    "æŒ‘æˆ°ï¼šæ•£è½åœ¨å„è™•çš„è³‡æ–™ (Data everywhere)\n",
    "åŸå› \n",
    "- Kaggleçš„è³‡æ–™åˆ†æåœ˜éšŠåœ¨ä¸€é–‹å§‹ï¼Œè³‡æ–™åŸºç¤è¨­æ–½ä¸ä½³ï¼Œè³‡æ–™ä¾†æºéå¸¸è¤‡é›œï¼Œç™¼ç¾è¨±å¤šäººåœ¨åšç›¸åŒçš„ç³»çµ±å»ºç«‹ä¸Š(å¦‚joinä¸åŒä¾†æºçš„è³‡æ–™)ï¼Œè³‡æ–™æˆé•·å¾—éå¸¸å¿«ï¼Œæœƒæœ‰ç™¼ç”Ÿcrashçš„é¢¨éšªã€‚\n",
    "ä¸åŒçš„è³‡æ–™ä¾†æºåˆ†æéç¨‹(åŸå…ˆ)\n",
    "- Back End Analytics(MSSQL DB): å¾è³‡æ–™åº«é€éSQL Explorer / Local(or GCP) MSSQL connector å»å–å¾—è³‡æ–™è½‰æ›æˆkaggle Datasetä¸¦åœ¨kernelsä¸­åšåˆ†æã€‚\n",
    "- Front End Analytics: å¾å‰ç«¯ç¶²é åŸ‹é»è§€å¯Ÿä½¿ç”¨è€…è¡Œç‚ºæ”¶é›†çš„è³‡æ–™åº«ï¼Œé€éBigQuery / Data Studioå–å¾—ã€ä½¿ç”¨è³‡æ–™å»åšåˆ†æã€‚\n",
    "- Google Analytics(è¼ƒå°‘ç”¨ï¼Œå¿½ç•¥)\n",
    "é€éETLæ•´åˆä¸åŒçš„è³‡æ–™ä¾†æº\n",
    "é–‹ç™¼æ™‚ç¨‹:\n",
    "- 2å€‹æœˆè¨­è¨ˆ\n",
    "- 3å€‹æœˆå¯¦ä½œ\n",
    "- 2å€‹æœˆè³‡æ–™éš±ç§review\n",
    "ç³»çµ±æ¶æ§‹:\n",
    "Data Source(Back End Analytics/Front End Analytics/Google Analytics) â†’ ETL(v1: Airflow, v2: Custom) â†’ Data Warehouse â†’ æ‡‰ç”¨å ´åŸŸ(kaggle note books/BigQuery/Dashboard/Kaggle Datasets)\n",
    "æˆæ•ˆ:\n",
    "- å…¬å¸å…§éƒ¨çš„ä»»ä½•äººéƒ½å¯ä»¥é€éData Warehouseç°¡æ˜“åœ°å–å¾—æƒ³ç²å–çš„è³‡æ–™ï¼Œæ”¹å–„äº†åŸå…ˆå¤§å®¶é‡è¤‡åœ°å¾ä¸åŒè³‡æ–™æºæ•´ç†åˆä½µåœ°éç¨‹ã€‚\n",
    "- ç”šè‡³å¯ä»¥é€éç°¡å–®çš„BigQuery UIç›´æ¥ç²å–è³‡æ–™ã€‚\n",
    "4. Lessons learned\n",
    "åŸºç¤è¨­æ–½æ˜¯è³‡æ–™ç§‘å­¸åœ˜éšŠçš„åŸºç¤\n",
    "- Hacking: å¯ä»¥å»å‰µå»ºä¸€æ¬¡æ€§çš„è§£æ³•ï¼Œä½†è¦è¨­ç«‹åœæé»å»å»ºç«‹åŸºç¤è¨­æ–½ï¼Œå¦‚: çœ‹åˆ°å¤§å®¶ä¸æ–·åœ¨åšç›¸åŒçš„äº‹æƒ…(æ•´åˆè³‡æ–™)ã€‚\n",
    "- Scale: è¶Šæ—©è€ƒæ…®è¶Šå¥½ï¼Œè³‡æ–™æœƒæˆé•·å¾—æ¯”æƒ³åƒä¸­å¿«ï¼Œè‹¥è¨­è¨ˆä¸å¥½ï¼Œå¯èƒ½æœƒç”¢ç”Ÿcrashé¢¨éšªã€‚\n",
    "- Vision: ç”¨æœ€å°çš„åŠªåŠ›å»é”åˆ°æœ€å¤§çš„æˆæ•ˆï¼Œå› æ­¤ï¼Œå»ºç«‹çš„ç³»çµ±å„ªå…ˆè§£æ±ºå¤§å¤šæ•¸äººæœ€ä¸»è¦çš„ç—›é»ã€‚\n",
    "é¿å…å®¢è£½åŒ–è»Ÿé«”ï¼Œå–„ç”¨ç¾æˆå·¥å…·\n",
    "å°¤å…¶åœ¨å°å…¬å¸ï¼Œç¶­è­·çš„æ™‚é–“æˆæœ¬ç‰¹åˆ¥é«˜ï¼Œä¸è«–æ˜¯è™•ç†å„è³‡æ–™åº«çš„äº¤äº’ç­‰ç­‰å•é¡Œï¼Œè‹¥å¯ä»¥ä½¿ç”¨ç¾æœ‰ç©©å®šçš„å·¥å…·ï¼Œå°±å»ä½¿ç”¨ã€‚\n",
    "- ä½¿ç”¨é–‹æºå·¥å…·æˆ–è€…æ˜¯ä»˜è²»çš„é›²ç«¯å·¥å…·ã€‚\n",
    "- è©¦è‘—ä¸è¦å®¢è£½åŒ–data connectors ä»¥åŠ ETLç³»çµ±ã€‚\n",
    "- ç¶­è­·å®¢è£½åŒ–çš„è»Ÿé«”éå¸¸ç—›è‹¦ï¼Œå°¤å…¶æ˜¯å°å…¬å¸ã€‚\n",
    "ä¸‰ã€åˆ†æç³»çµ± (Analytics systems)\n",
    "æŒ‘æˆ°ï¼šåŸºç¤è¨­æ–½å»ºç«‹ä¹‹å¾Œï¼Œå¤ªå¤šåˆ†æéœ€æ±‚éœ€è¦è™•ç†ï¼Œå¦‚ä½•åˆ¶å®šå„ªå…ˆé †åºä»¥åŠè§£æ±ºæ–¹æ¡ˆã€‚\n",
    "åŸå› \n",
    "- ä¸åŒéƒ¨é–€çš„éœ€æ±‚çœ¾å¤šå¦‚: æœ‰å¤šå°‘TensorFlow vs PyTorchå€‹åˆ¥ä½¿ç”¨è€…? æœ‰å¤šå°‘ä½¿ç”¨è€…åœ¨Fortune500å¤§å…¬å¸? å¯ä»¥å»ºç«‹Dashboardå—? å¯ä»¥å»ºç«‹ä¸€å€‹åˆ†æä¸¦ç”¢å‡ºå ±è¡¨å—?\n",
    "- åœ¨çœ¾å¤šéœ€æ±‚ä¹‹ä¸‹ï¼Œè³‡æ–™åˆ†æéƒ¨é–€éœ€è¦æ’åˆ—å„ªå…ˆé †åºä»¥åŠå¿…è¦æ€§ï¼Œå°æ–¼å…¬å¸çš„æ–‡åŒ–ä¹Ÿé–‹å§‹çœŸæ­£çš„è½‰è®Šã€‚\n",
    "åˆ†æå„ªå…ˆ (Analytics first)\n",
    "åˆ†æçš„CPå€¼éå¸¸é«˜ï¼Œé›–ç„¶æˆ‘å€‘éƒ½æƒ³è¦åšMLï¼Œä½†æœ‰çš„æ™‚å€™åˆ†æå°±è¶³å¤ å»è§£æ±ºå¤§éƒ¨åˆ†çš„å•é¡Œã€‚\n",
    "\n",
    "- Drive value, deliver insights, build intuition\n",
    "a. Superpower:\n",
    "å¾è³‡æ–™ä¸­å–å¾—å‹•è¦‹ï¼Œé©…å‹•/æ”¯æŒå•†æ¥­æ±ºç­–ã€‚\n",
    "b. Build data intuition for ML definition:\n",
    "å› ç‚ºè¨±å¤šåšMLçš„äººå“¡å…¶å¯¦å°ˆæ³¨æ–¼æŠ€è¡“æœ¬èº«ï¼Œä½†ä¸¦æ²’æœ‰å¦¥å–„åœ°çµåˆå•†æ¥­åƒ¹å€¼ï¼Œè¨±å¤šçš„å°ˆæ¡ˆæœ€å¾Œæ˜¯æ²’æœ‰ç”¢ç”Ÿimpactï¼Œå› æ­¤å¾åˆ†æä¸­å»ºç«‹å°å•†æ¥­å•é¡Œã€åƒ¹å€¼çš„ç†è§£æ˜¯å¿…ä¸å¯å°‘çš„ã€‚\n",
    "\n",
    "- Determine centralized or distributed Data Science team\n",
    "a. Centralized:\n",
    "å°‡è³‡æ–™ç§‘å­¸åœ˜éšŠå£¯å¤§ï¼Œå°ˆé–€å»è™•ç†å„éƒ¨é–€çš„åˆ†æå•é¡Œã€‚\n",
    "b. Distributed:\n",
    "é€éè«®è©¢ã€åˆ†äº«ï¼Œå¦‚çµ¦ä¸€å€‹ç°¡å–®çš„ä¾‹å­è®“éƒ¨é–€çš„äººå­¸ç¿’ï¼Œå°‡åˆ†æçš„æ–‡åŒ–æ¤å…¥å„éƒ¨é–€ï¼Œè®“å„éƒ¨é–€çš„äººä¹Ÿå¯ä»¥æœ‰åˆ†æèƒ½åŠ›ï¼Œä¹Ÿæ˜¯ Wendy åœ¨ Kaggle æ™‚æ¡ç”¨çš„æ–¹æ³•ã€‚\n",
    "\n",
    "- Give people freedom to choose tools\n",
    "a. Can always consolidate later:\n",
    "è®“å¤§å®¶å¤šå»ä½¿ç”¨ç³»çµ±ç‚ºå„ªå…ˆï¼Œå…ˆå»ºç«‹èµ·data-drivençš„æ–‡åŒ–ã€‚\n",
    "\n",
    "- Analytics or ML?\n",
    "a. Be patient. ML system is hard! ML system takes time to define, build and to tune\n",
    "b. Deliver analytics results quickly\n",
    "c. In the meantime, you lay the groundwork for ML (usually infrastructure is shared)\n",
    "åˆ†æç³»çµ± (Analytics systems)\n",
    "\n",
    "Analytics systems\n",
    "4. ä¾‹å­ (A workflow example)\n",
    "\n",
    "Workflow example\n",
    "åœ¨å»ºç«‹äº†åŸºç¤è¨­æ–½ä¹‹å¾Œï¼ŒåŸå…ˆéœ€è¦å°ˆé–€ä¸€å€‹å·¥ç¨‹å¸«åšçš„åˆ†æå·¥ä½œ(æ›´æ–°Kaggle æœ€å¸¸ç”¨çš„packageåˆ°kernelä¸Š)ï¼Œå¯ä»¥é€é BigQuery å»è‡ªå‹•åœ¨é›²ç«¯é‹è¡Œï¼Œç¯€çœäº†ä»¥å¾€äººå·¥çš„éƒ¨åˆ†ã€‚\n",
    "å››ã€æ©Ÿå™¨å­¸ç¿’ (Machine learning)\n",
    "æŒ‘æˆ°ï¼šä¸€å€‹å•é¡Œé€šå¸¸éƒ½æœ‰è¨±å¤šè§£æ±ºæ–¹æ³•ï¼Œä½ éœ€è¦å»æ‰¾åˆ°è­‰æ“šå»æ”¯æŒç¾æœ‰çš„æ–¹æ³•ä¸å¤ å¥½ï¼Œéœ€è¦å»å»ºç«‹MLæ–¹æ³•ï¼Œåœ¨é€”ä¸­é‡åˆ°çš„æŒ‘æˆ°ã€‚\n",
    "ç‚ºä»€éº¼ä¸ä½¿ç”¨heuristics (Why donâ€™t we use heuristics?)\n",
    "- åœ¨åšMLçš„æ™‚å€™ï¼Œä¸€å®šæœƒæœ‰å¾ˆå¤šäººå•åˆ°ç‚ºä»€éº¼éœ€è¦ML?ç‚ºä»€éº¼ä¸ç­‰ä¸€æ®µæ™‚é–“å¾—åˆ°çœŸå¯¦è³‡æ–™å¾Œå»åšçµ±è¨ˆé‡ç•¶åšvalue?(heuristics)\n",
    "- æˆ–è€…ç‚ºä»€éº¼è¦é¸æ“‡å»ºç«‹ä¸€å€‹éœ€è¦æ™‚æ™‚ç¶­è­·ã€æ›´æ–°ä»¥åŠç›£æ§çš„MLç³»çµ±ï¼Œéœ€è¦å¤§é‡çš„è³‡æ–™æ¨™ç±¤ä»¥åŠå…¶ä»–å·¥ç¨‹?\n",
    "Lessons learned\n",
    "- Itâ€™s okay to use heuristics:\n",
    "a. é¦–å…ˆä¸€å®šè¦è€ƒæ…®MLçš„å¿…è¦æ€§ï¼Œå¦‚æœæ²’æœ‰è³‡æ–™å°±å…ˆå»å–å¾—è³‡æ–™æˆ–è€…è€ƒæ…®å–å¾—çš„æˆæœ¬èˆ‡æ•ˆç›Šæ˜¯å¦åˆç†ã€‚\n",
    "b. å…ˆç”¨heuristicsæ–¹æ³•å»è§£æ±ºå•é¡Œï¼Œçœ‹çµæœæ˜¯å¦å·²ç¶“è¶³å¤ å¥½äº†ï¼Œå†æ±ºå®šæ˜¯å¦ç¹¼çºŒã€‚\n",
    "\n",
    "- éœ€è¦åšä¸€äº›å¯¦é©—ç¢ºèªéœ€è¦MLå»è§£æ±ºå•é¡Œ (It takes some experiment to show you really do need ML):\n",
    "a. å…ˆåš PoC å»å˜—è©¦ï¼Œç¢ºä¿æœ‰æ˜¯æ½›åŠ›çš„ã€‚\n",
    "b. ä¿æŒ PoC ç°¡å–®ï¼Œä¸è«–æ˜¯æ¼”ç®—æ³•æˆ–è€…æ˜¯ç³»çµ±ã€‚\n",
    "c. ç‚ºäº†é€Ÿåº¦ã€æ•ˆèƒ½ä»¥åŠä½¿ç”¨è€…é«”é©—ï¼Œå…ˆç”¨ç¾å­˜çš„MLæœå‹™å»å»ºæ§‹PoCæ˜¯å®Œå…¨æ²’å•é¡Œçš„ã€‚å¯ä»¥åœ¨ç¢ºå®šæœ‰æ½›åŠ›ä¹‹å¾Œï¼Œå†å»ºç«‹æ›´å®¢è£½åŒ–çš„æœå‹™ã€‚\n",
    "\n",
    "(è£œ: å¯ä»¥é€é åƒåŠ æ¯”è³½(kaggle) è¨“ç·´å¿«é€Ÿéµç«‹prototypeçš„èƒ½åŠ›)\n",
    "\n",
    "- å¦‚ä½•å»èªªæœå…¬å¸éœ€è¦ML (How to convince people?)\n",
    "a. å¾é ˜å°è€…/æ±ºç­–è€…çš„è§€é»å‡ºç™¼å»æ€è€ƒã€‚\n",
    "b. æå‡ºç´°ç¯€çš„åˆ†æï¼Œé€éæˆæœ¬/æ”¶ç›Šçš„è³‡æ–™åˆ†æä½è­‰ä¾†èªªæœæŠ•è³‡æ˜¯å€¼å¾—çš„ã€‚\n",
    "æ‰¾åˆ°é©åˆçš„é¡Œç›®å»é æ¸¬ (Picking a â€œthingâ€ to predict)\n",
    "- åœ¨æ‰¾å°‹10é¤˜å€‹é¡Œç›®ä¹‹å¾Œï¼ŒæˆåŠŸå¯¦ç¾2å€‹\n",
    "\n",
    "- å…¶ä¸­ä¹‹ä¸€æ˜¯ notebookçš„å“è³ªé æ¸¬\n",
    "a. notebookå“è³ªå°æ–¼æ’åº/å¾—åˆ†/éæ¿¾ç­‰ç­‰å·¥ä½œæ˜¯æœ‰å¹«åŠ©çš„ã€‚\n",
    "b. å°å¤šå€‹éƒ¨é–€éƒ½æœ‰ç›Šï¼Œå¯ä»¥åœ¨ä¸åŒçš„éƒ¨é–€ä¸­åˆ†äº«ï¼Œå› æ­¤æ±ºå®šæ­¤é¡Œç›®ã€‚\n",
    "\n",
    "- æå‡ºæ­£ç¢ºç­”æ¡ˆæ˜¯éå¸¸é›£çš„(ä¸‹åˆ—ç‚ºé€”ä¸­é‡åˆ°çš„é›£é¡Œã€æŒ‘æˆ°)\n",
    "a. notebookå“è³ªæ˜¯éå¸¸ä¸»è§€çš„ã€‚\n",
    "b. é€éä½¿ç”¨è€…è¡¨ç¾å°‹æ‰¾æ›¿ä»£æ¨™æº–ã€‚\n",
    "c. èŠ±è²»æ›´å¤šçš„æ™‚é–“åœ¨ground truthå®šç¾©ä¸Š, è€Œä¸æ˜¯æ¨¡å‹å»ºç«‹ã€‚\n",
    "d. å…ˆå‰å»ºç«‹çš„è³‡æ–™åˆ†æçµæœå°±åœ¨æ­¤è™•å¹«åŠ©å¾ˆå¤§ã€‚\n",
    "e. ä¸æ–·èˆ‡stakeholders(å¦‚ç”¢å“æ±ºç­–è€…)ç¢ºèªç›®å‰å‡è¨­æ˜¯å¦æ­£ç¢ºã€‚\n",
    "æˆåŠŸæŒ‡æ¨™ (Success metrics)\n",
    "- ç¢ºèªstakeholders\n",
    "a. èª°æœƒå»ä½¿ç”¨é æ¸¬çµæœ/æœƒå¦‚ä½•ä½¿ç”¨ã€‚\n",
    "b. èª°æœƒæŠ•è³‡æˆ‘çš„æ¨¡å‹ã€‚\n",
    "\n",
    "- æå‡ºå•†æ¥­/ç”¢å“æŒ‡æ¨™\n",
    "a. å•†æ¥­æŒ‡æ¨™èˆ‡MLæŒ‡æ¨™æœ‰å¯èƒ½ä¸ä¸€æ¨£ã€‚\n",
    "b. MLæŒ‡æ¨™ä»¥æ•¸å­¸ä¸Šåˆç†ç‚ºå„ªå…ˆ(å¦‚PR-AUC, Accuracyç­‰ç­‰)\n",
    "c. ç›¡é‡ä½¿å•†æ¥­æŒ‡æ¨™èˆ‡æ•¸å­¸æŒ‡æ¨™æ–¹å‘ä¸€è‡´ï¼Œä½†é€™ä¸å®¹æ˜“ï¼Œå¦‚: æœ‰æ™‚å€™å•†æ¥­æŒ‡æ¨™åªå°ˆæ³¨æ–¼å‰10%è³‡æ–™çš„æº–ç¢ºåº¦ã€‚\n",
    "\n",
    "- èˆ‡stakeholdersè¨­å®šæ¨¡å‹è¡¨ç¾ç›®æ¨™\n",
    "ä¾‹: å¦‚æœæ¨¡å‹è¡¨ç¾æŒ‡æ¨™é”åˆ°x%, å°‡æœƒæ›¿å…¬å¸çœä¸‹ $Y, å°±launchæ¨¡å‹ã€‚\n",
    "\n",
    "- å¦‚æœéœ€è¦é‡æ–°å®šç¾©æ¨¡å‹æˆåŠŸæŒ‡æ¨™ï¼Œä¸æ–·æºé€šç¢ºä¿é›™æ–¹èªçŸ¥ä¸€è‡´ã€‚\n",
    "BigQueryMLä½¿ç”¨ç¶“é©— (Experience with BigQueryML)\n",
    "ç°¡å–®æ˜“ç”¨\n",
    "Data wrangling åœ¨SQLå…§å®Œæˆ\n",
    "æ¨¡å‹åœ¨SQLå…§å»ºç«‹å®Œæˆ\n",
    "ç–Šä»£æ¨¡å‹å¿«é€Ÿ\n",
    "èˆ‡TF hubç›¸å®¹ï¼Œèƒ½å¤ å¾å‰è€…import TF æ¨¡å‹\n",
    "AutoMLä½¿ç”¨ç¶“é©— (Experience with AutoML)\n",
    "ç°¡å–®æ˜“ç”¨\n",
    "ç¯€çœé–‹ç™¼æ™‚é–“\n",
    "ç‰¹å¾µç¯©é¸: ç‰¹å¾µæ•ˆæœå¿«é€Ÿæª¢é©—\n",
    "ä¾¿å®œ: 3å°æ™‚ $ 5\n",
    "æœ€å¾Œæ²’æœ‰ç”¨åœ¨ç”Ÿç”¢ç’°å¢ƒï¼Œä½†å¦‚æœè¦åœ¨ç”Ÿç”¢ç’°å¢ƒæ‡‰ä¸å›°é›£\n",
    "å°‡MLå°å…¥ç”Ÿç”¢ç’°å¢ƒä¸­ (Putting it in production)\n",
    "\n",
    "system structure\n",
    "ä¿æŒç³»çµ±ç°¡å–®ï¼Œä½¿å¾—ç¶­è­·å®¹æ˜“ï¼Œç¬¬ä¸€æ¬¡å˜—è©¦å¯ä»¥å¿½ç•¥éƒ¨åˆ†componentsã€‚\n",
    "è³‡æ–™åŒæ­¥\n",
    "ç‰¹å¾µ\n",
    "è¨“ç·´\n",
    "ç›£æ§\n",
    "æ¨è«–/é æ¸¬\n",
    "æ¶æ§‹ (What we ended up with)\n",
    "\n",
    "Our choice, Kaggle\n",
    "\n",
    "Training\n",
    "\n",
    "Inference\n",
    "çµè«– (Conclusions)\n",
    "å°æ¯”å¤§å…¬å¸ï¼Œå°å…¬å¸é¢è‡¨çš„æŒ‘æˆ°æ˜¯å¾ˆä¸ä¸€æ¨£çš„ã€‚\n",
    "å³ä¾¿æ˜¯Kaggleé€™ç¨®ä»¥è³‡æ–™ç§‘å­¸ç‚ºä¸»çš„å…¬å¸ï¼Œè¦èªªæœå»åšMLå°ˆæ¡ˆä¹Ÿæ˜¯ä¸å®¹æ˜“çš„ï¼Œå› ç‚ºå…¶æˆæœ¬/è³‡æ–™è¦æ±‚é«˜ã€‚\n",
    "è—‰ç”±è€å¿ƒã€ç¶“é©—ä»¥åŠç´°å¿ƒé©—è­‰ï¼Œå¯ä»¥åœ¨æˆæœ¬èˆ‡æ”¶ç›Šä¹‹é–“æ‰¾åˆ°å¹³è¡¡ã€‚\n",
    "\"\"\"\n",
    "\n",
    "# æˆ‘è‡ªå·±çš„mediumæ–‡ç« , æ‰¾å–®å€‹å­—\n",
    "kw_model = KeyBERT(model='distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cjm3Q2iAm6JI",
    "outputId": "61cc2b26-3443-4159-a154-3fc60cce23e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science team centralized å°‡è³‡æ–™ç§‘å­¸åœ˜éšŠå£¯å¤§', 0.0352),\n",
       " ('è³‡æ–™ç§‘å­¸åœ˜éšŠçš„å»ºç«‹æœƒé¢è‡¨è‘—ä¸ä¸€æ¨£çš„æŒ‘æˆ° è®“æˆ‘å€‘è·Ÿè‘— wendy äº†è§£å…¶åœ¨ kaggle', 0.1037),\n",
       " ('å»ºç«‹è³‡æ–™ç§‘å­¸åœ˜éšŠ éš¨è‘—è³‡æ–™ç§‘å­¸åœ¨å„é ˜åŸŸçš„é–‹ç™¼ æ‡‰ç”¨æŒçºŒå‡æº«', 0.1345),\n",
       " ('å»ºç«‹å°ˆæ¥­åˆ†å·¥çš„åœ˜éšŠæ˜¯å¿…ç¶“ä¹‹è·¯ è³‡æ–™ç§‘å­¸åœ˜éšŠçš„å»ºç«‹æœƒé¢è‡¨è‘—ä¸ä¸€æ¨£çš„æŒ‘æˆ° è®“æˆ‘å€‘è·Ÿè‘— wendy äº†è§£å…¶åœ¨', 0.0759),\n",
       " ('éš¨è‘—è³‡æ–™ç§‘å­¸åœ¨å„é ˜åŸŸçš„é–‹ç™¼ æ‡‰ç”¨æŒçºŒå‡æº« å»ºç«‹å°ˆæ¥­åˆ†å·¥çš„åœ˜éšŠæ˜¯å¿…ç¶“ä¹‹è·¯', 0.1593)]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_model.extract_keywords(doc, use_maxsum=True, top_n=5, keyphrase_ngram_range=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ieec-UknN7K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "é—œéµå­—æå–.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "138b5b358c4843779f9fe6e06a056aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38f2d80a2808438bb9fe16cca2f03d62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40763304fcb745ea9c08ac1e5c80580f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5357ebb9024f41d9bc733a5c529257f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38f2d80a2808438bb9fe16cca2f03d62",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f14034beff874cb194445e6a4928c016",
      "value": " 245M/245M [00:14&lt;00:00, 16.5MB/s]"
     }
    },
    "7b32383d01fe4695aecd70a4329dfc17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae9402350f5643c583434f08925377e6",
       "IPY_MODEL_5357ebb9024f41d9bc733a5c529257f6"
      ],
      "layout": "IPY_MODEL_138b5b358c4843779f9fe6e06a056aa0"
     }
    },
    "a347223aaf374e5692cb5ab572fdc91e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae9402350f5643c583434f08925377e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a347223aaf374e5692cb5ab572fdc91e",
      "max": 244733649,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40763304fcb745ea9c08ac1e5c80580f",
      "value": 244733649
     }
    },
    "f14034beff874cb194445e6a4928c016": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
